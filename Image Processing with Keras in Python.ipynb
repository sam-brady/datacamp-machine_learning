{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing With Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGES AS DATA: VISUALIZATIONS\n",
    "\n",
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "data = plt.imread('bricks.png')\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGES AS DATA: CHANGING TH EIMAGES\n",
    "\n",
    "# Set the red channel in this part of the image to 1\n",
    "data[:10,:10,0] = 1\n",
    "\n",
    "# Set the green channel in this part of the image to 0\n",
    "data[:10,:10,1] = 0\n",
    "\n",
    "# Set the blue channel in this part of the image to 0\n",
    "data[:10,:10,2] = 0\n",
    "\n",
    "# Visualize the result\n",
    "plt.imshow(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING ONE HOT ENCODING TO REPRESENT IMAGES\n",
    "\n",
    "# The number of image categories\n",
    "n_categories = 3\n",
    "\n",
    "# The unique values of categories in the data\n",
    "categories = np.array([\"shirt\", \"dress\", \"shoe\"])\n",
    "\n",
    "# Initialize ohe_labels as all zeros\n",
    "ohe_labels = np.zeros((len(labels), n_categories))\n",
    "\n",
    "# Loop over the labels\n",
    "for ii in range(len(labels)):\n",
    "    # Find the location of this label in the categories variable\n",
    "    jj = np.where(categories == labels[ii])\n",
    "    # Set the corresponding zero to one\n",
    "    ohe_labels[ii, jj] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATING A CLASSIFIER\n",
    "\n",
    "# Calculate the number of correct predictions\n",
    "number_correct = (test_labels*predictions).sum()\n",
    "print(number_correct)\n",
    "\n",
    "# Calculate the proportion of correct predictions\n",
    "proportion_correct = number_correct/len(predictions)\n",
    "print(proportion_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD A NEURAL NETWROK\n",
    "\n",
    "# Imports components from Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initializes a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# First layer\n",
    "model.add(Dense(10, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# Second layer\n",
    "model.add(Dense(10, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPILE A NEURAL NETWORK\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "           loss='categorical_crossentropy', \n",
    "           metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FITTING A NEURAL NETWORK TO CLOTHING DATA\n",
    "\n",
    "\n",
    "# Reshape the data to two-dimensional array\n",
    "train_data = train_data.reshape(50, 784)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(train_data, train_labels, validation_split=0.2, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROSS. VALIDATION FOR A NEURAL NETWORK EVALUATION\n",
    "\n",
    "# Reshape test data\n",
    "test_data = test_data.reshape(10, 784)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(test_data, test_labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE DIMENSIONAL CONVOLUTIONS\n",
    "\n",
    "\n",
    "array = np.array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0])\n",
    "kernel = np.array([1, -1, 0])\n",
    "conv = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "# Output array\n",
    "for ii in range(8):\n",
    "    conv[ii] = (kernel * array[ii:ii+3]).sum()\n",
    "\n",
    "# Print conv\n",
    "print(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE CONVOLUTIONS\n",
    "\n",
    "\n",
    "kernel = np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]])\n",
    "result = np.zeros(im.shape)\n",
    "\n",
    "# Output array\n",
    "for ii in range(im.shape[0] - 3):\n",
    "    for jj in range(im.shape[1] - 3):\n",
    "        result[ii, jj] = (im[ii:ii+3, jj:jj+3] * kernel).sum()\n",
    "\n",
    "# Print result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINING IMAGE CONVOLUTION KERNELS (horizontal, light spot, dark spot)\n",
    "\n",
    "\n",
    "kernel = np.array([[-1, -1, -1], \n",
    "                   [1, 1, 1],\n",
    "                   [-1, -1, -1]])\n",
    "\n",
    "\n",
    "kernel = np.array([[-1, -1, -1], \n",
    "                           [-1, 1, -1],\n",
    "                           [-1, -1, -1]])\n",
    "\n",
    "\n",
    "kernel = np.array([[1, 1, 1], \n",
    "                   [1, -1, 1],\n",
    "                   [1, 1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVOLUTION NETWROK FRO IMAGE CLASSIFICATION\n",
    "\n",
    "\n",
    "# Import the necessary components from Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "# Initialize the model object\n",
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer\n",
    "model.add(Conv2D(10, kernel_size=3, activation='relu', \n",
    "               input_shape=(img_rows,img_cols, 1)))\n",
    "\n",
    "# Flatten the output of the convolutional layer\n",
    "model.add(Flatten())\n",
    "# Add an output layer for the 3 categories\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING A CNN TO CLASSIFY CLOTHING TYPES\n",
    "\n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model on a training set\n",
    "model.fit(train_data, train_labels, \n",
    "          validation_split=0.2, \n",
    "          epochs=3, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE A CNN WITH TEST DATA\n",
    "\n",
    "\n",
    "# Evaluate the model on separate test data\n",
    "model.evaluate(test_data,test_labels, batch_size=10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDING PADDING TO A CNN\n",
    "\n",
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the convolutional layer\n",
    "model.add(Conv2D(10, kernel_size=3, activation='relu', \n",
    "                 input_shape=(img_rows, img_cols, 1), \n",
    "                 padding='same'))\n",
    "\n",
    "# Feed into output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDING STRIDES\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the convolutional layer\n",
    "model.add(Conv2D(10, kernel_size=3, activation='relu', \n",
    "              input_shape=(img_rows, img_cols, 1), \n",
    "              strides= 2))\n",
    "\n",
    "# Feed into output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going Deeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING A DEEP LEARNING NETWORK\n",
    "\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer (15 units)\n",
    "model.add(Conv2D(15, kernel_size=2, activation='relu', input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "\n",
    "# Add another convolutional layer (5 units)\n",
    "model.add(Conv2D(5, kernel_size=2, activation='relu'))\n",
    "\n",
    "# Flatten and feed to output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN A DEEP NN TO CLASSIFY CLOTHING IMAGES\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model to training data \n",
    "model.fit(train_data, train_labels, \n",
    "          validation_split=0.2, \n",
    "          epochs=3, batch_size=10)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "model.evaluate(test_data, test_labels, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOW MANY PARAMETERS IN A ADEEP CNN\n",
    "\n",
    "\n",
    "# CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(10, kernel_size=2, activation='relu', \n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(10, kernel_size=2, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Summarize the model \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR OWN POOLING OPERATION\n",
    "\n",
    "# Result placeholder\n",
    "result = np.zeros((im.shape[0]//2, im.shape[1]//2))\n",
    "\n",
    "# Pooling operation\n",
    "for ii in range(result.shape[0]):\n",
    "    for jj in range(result.shape[1]):\n",
    "        result[ii, jj] = np.max(im[ii*2:ii*2+2,jj*2:jj*2+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KERAS POOLING LAYERS\n",
    "\n",
    "\n",
    "# Add a convolutional layer\n",
    "model.add(Conv2D(15, kernel_size=2, activation='relu', \n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "# Add a pooling operation\n",
    "model.add(MaxPool2D(2))\n",
    "\n",
    "# Add another convolutional layer\n",
    "model.add(Conv2D(5, kernel_size=2, activation='relu'))\n",
    "\n",
    "# Flatten and feed to output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN A DEEP CNN WITH POOLING TO CLASSIFY IMAGES\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "           loss='categorical_crossentropy', \n",
    "           metrics=['accuracy'])\n",
    "\n",
    "# Fit to training data\n",
    "model.fit(train_data, train_labels, batch_size=10, epochs=3, validation_split=0.2)\n",
    "\n",
    "# Evaluate on test data \n",
    "model.evaluate(test_data, test_labels, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding and Improving Deep Convolutional Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT THE LEARNING CURVES\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train the model and store the training object\n",
    "training = model.fit(train_data, train_labels, validation_split=0.2, epochs=3, batch_size=10)\n",
    "\n",
    "# Extract the history from the training object\n",
    "history = training.history\n",
    "\n",
    "# Plot the training loss \n",
    "plt.plot(history['loss'])\n",
    "# Plot the validation loss\n",
    "plt.plot(history['val_loss'])\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING STORED WEIGHTS TO PREDICT IN A TEST SET\n",
    "\n",
    "# Load the weights from file\n",
    "model.load_weights('weights.hdf5')\n",
    "\n",
    "# Predict from the first three images in the test data\n",
    "model.predict(test_data[0:3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDING A DROPOUT TO YOUR NETWORK\n",
    "\n",
    "# Add a convolutional layer\n",
    "model.add(Conv2D(15, kernel_size=2, activation='relu', \n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "# Add a dropout layer\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Add another convolutional layer\n",
    "model.add(Conv2D(5, kernel_size=2, activation='relu'))\n",
    "\n",
    "# Flatten and feed to output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD BATCH NORMALIZATION\n",
    "\n",
    "# Add a convolutional layer\n",
    "model.add(Conv2D(15, kernel_size=2, activation='relu', input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "\n",
    "# Add batch normalization layer\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Add another convolutional layer\n",
    "model.add(Conv2D(5, kernel_size=2, activation='relu'))\n",
    "\n",
    "# Flatten and feed to output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACTING A KERNEL FROM A TRAINED MODEL\n",
    "\n",
    "\n",
    "# Load the weights into the model\n",
    "model.load_weights('weights.hdf5')\n",
    "\n",
    "# Get the first convolutional layer from the model\n",
    "c1 = model.layers[0]\n",
    "\n",
    "# Get the weights of the first convolutional layer\n",
    "weights1 = c1.get_weights()\n",
    "\n",
    "# Pull out the first channel of the first kernel in the first layer\n",
    "kernel = weights1[0][...,0, 0]\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZING KERNEL RESPONSES\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convolve with the fourth image in test_data\n",
    "out = convolution(test_data[3, :, :, 0], kernel)\n",
    "\n",
    "# Visualize the result\n",
    "plt.imshow(out)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
