{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING A SPARK SESSION\n",
    "\n",
    "\n",
    "# Import the PySpark module\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create SparkSession object\n",
    "spark = SparkSession.builder \\\n",
    "                    .master('local[*]') \\\n",
    "                    .appName('test') \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "# What version of Spark?\n",
    "print(spark.version)\n",
    "\n",
    "# Terminate the cluster\n",
    "spark.stop()3ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING FLIGHTS DATA\n",
    "\n",
    "# Read data from CSV file\n",
    "flights = spark.read.csv('flights.csv',\n",
    "                         sep=',',\n",
    "                         header=True,\n",
    "                         inferSchema=True,\n",
    "                         nullValue='NA')\n",
    "\n",
    "# Get number of records\n",
    "print(\"The data contain %d records.\" % flights.count())\n",
    "\n",
    "# View the first five records\n",
    "flights.show(5)\n",
    "\n",
    "# Check column data types\n",
    "flights.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING SMS SPAM DATA\n",
    "\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "# Specify column names and types\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType()),\n",
    "    StructField(\"text\", StringType()),\n",
    "    StructField(\"label\", IntegerType())\n",
    "])\n",
    "\n",
    "# Load data from a delimited file\n",
    "sms = spark.read.csv('sms.csv', sep=';', header=False, schema=schema)\n",
    "\n",
    "# Print schema of DataFrame\n",
    "sms.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVING COLUMNS AND ROWS\n",
    "\n",
    "\n",
    "# Remove the 'flight' column\n",
    "flights = flights.drop('flight')\n",
    "\n",
    "# Number of records with missing 'delay' values\n",
    "flights.filter('delay IS NULL').count()\n",
    "\n",
    "# Remove records with missing 'delay' values\n",
    "flights = flights.filter('delay IS NOT NULL')\n",
    "\n",
    "# Remove records with missing values in any column and get the number of remaining rows\n",
    "flights = flights.dropna()\n",
    "print(flights.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLUMN MANIPULATION\n",
    "\n",
    "\n",
    "# Import the required function\n",
    "from pyspark.sql.functions import round\n",
    "\n",
    "# Convert 'mile' to 'km' and drop 'mile' column\n",
    "flights_km = flights.withColumn('km', round(flights.mile * 1.60934, 0)) \\\n",
    "                    .drop('mile')\n",
    "\n",
    "# Create 'label' column indicating whether flight delayed (1) or not (0)\n",
    "flights_km = flights_km.withColumn('label', (flights_km.delay >= 15).cast('integer'))\n",
    "\n",
    "# Check first five records\n",
    "flights_km.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CATEGORICAL COLUMNS\n",
    "\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Create an indexer\n",
    "indexer = StringIndexer(inputCol='carrier', outputCol='carrier_idx')\n",
    "\n",
    "# Indexer identifies categories in the data\n",
    "indexer_model = indexer.fit(flights)\n",
    "\n",
    "# Indexer creates a new column with numeric index values\n",
    "flights_indexed = indexer_model.transform(flights)\n",
    "\n",
    "# Repeat the process for the other categorical feature\n",
    "flights_indexed = StringIndexer(inputCol='org', outputCol='org_idx').fit(flights_indexed).transform(flights_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSEMBLING COLUMNS\n",
    "\n",
    "\n",
    "# Import the necessary class\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Create an assembler object\n",
    "assembler = VectorAssembler(inputCols=[\n",
    "    'mon', 'dom', 'dow', 'carrier_idx', 'org_idx','km', 'depart', 'duration'\n",
    "], outputCol='features')\n",
    "\n",
    "# Consolidate predictor columns\n",
    "flights_assembled = assembler.transform(flights)\n",
    "\n",
    "# Check the resulting column\n",
    "flights_assembled.select('features', 'delay').show(5, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TEST SPLIT\n",
    "\n",
    "\n",
    "# Split into training and testing sets in a 80:20 ratio\n",
    "flights_train, flights_test = flights.randomSplit([0.8, 0.2], seed=17)\n",
    "\n",
    "# Check that training set has around 80% of records\n",
    "training_ratio = flights_train.count() / flights.count()\n",
    "print(training_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD A DECISION TREE\n",
    "\n",
    "# Import the Decision Tree Classifier class\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# Create a classifier object and fit to the training data\n",
    "tree = DecisionTreeClassifier()\n",
    "tree_model = tree.fit(flights_train)\n",
    "\n",
    "# Create predictions for the testing data and take a look at the predictions\n",
    "prediction = tree_model.transform(flights_test)\n",
    "prediction.select('label', 'prediction', 'probability').show(5, False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE A DECISION TREE\n",
    "\n",
    "\n",
    "# Create a confusion matrix\n",
    "prediction.groupBy('label', 'prediction').count().show()\n",
    "\n",
    "# Calculate the elements of the confusion matrix\n",
    "TN = prediction.filter('prediction = 0 AND label = prediction').count()\n",
    "TP = prediction.filter('prediction = 1 AND label = prediction').count()\n",
    "FN = prediction.filter('prediction = 0 AND label != prediction').count()\n",
    "FP = prediction.filter('prediction = 1 AND label != prediction').count()\n",
    "\n",
    "# Accuracy measures the proportion of correct predictions\n",
    "accuracy = (TN +TP)/(TN+TP+FN+FP)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD A LOGISTIC REGRESSION MODEL\n",
    "\n",
    "# Import the logistic regression class\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Create a classifier object and train on training data\n",
    "logistic = LogisticRegression().fit(flights_train)\n",
    "\n",
    "# Create predictions for the testing data and show confusion matrix\n",
    "prediction = logistic.transform(flights_test)\n",
    "prediction.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE THE LOGISTIC REGRESSION MODEL\n",
    "\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision = TP/(TP+FP)\n",
    "recall = TP/(TP+FN)\n",
    "print('precision = {:.2f}\\nrecall    = {:.2f}'.format(precision, recall))\n",
    "\n",
    "# Find weighted precision\n",
    "multi_evaluator = MulticlassClassificationEvaluator()\n",
    "weighted_precision = multi_evaluator.evaluate(prediction, {multi_evaluator.metricName: \"weightedPrecision\"})\n",
    "\n",
    "# Find AUC\n",
    "binary_evaluator = BinaryClassificationEvaluator()\n",
    "auc = binary_evaluator.evaluate(prediction, {binary_evaluator.metricName: 'areaUnderROC'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PUNCTUATION NUMBERS AND TOKENS\n",
    "\n",
    "\n",
    "# Import the necessary functions\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "\n",
    "# Remove punctuation (REGEX provided) and numbers\n",
    "wrangled = sms.withColumn('text', regexp_replace(sms.text, '[_():;,.!?\\\\-]', ' '))\n",
    "wrangled = wrangled.withColumn('text', regexp_replace(wrangled.text, '[0-9]', ' '))\n",
    "\n",
    "# Merge multiple spaces\n",
    "wrangled = wrangled.withColumn('text', regexp_replace(wrangled.text, ' +', ' '))\n",
    "\n",
    "# Split the text into words\n",
    "wrangled = Tokenizer(inputCol='text', outputCol='words').transform(wrangled)\n",
    "\n",
    "wrangled.show(4, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOPWORDS AND HASHING\n",
    "\n",
    "\n",
    "from pyspark.ml.feature import StopWordsRemover, HashingTF, IDF\n",
    "\n",
    "# Remove stop words.\n",
    "wrangled = StopWordsRemover(inputCol='words', outputCol='terms')\\\n",
    "      .transform(sms)\n",
    "\n",
    "# Apply the hashing trick\n",
    "wrangled = HashingTF(inputCol='terms', outputCol='hash', numFeatures=1024)\\\n",
    "      .transform(wrangled)\n",
    "\n",
    "# Convert hashed symbols to TF-IDF\n",
    "tf_idf = IDF(inputCol='hash', outputCol='features')\\\n",
    "      .fit(wrangled).transform(wrangled)\n",
    "      \n",
    "tf_idf.select('terms', 'features').show(4, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING A SPAM CLASSIFIER\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "sms_train, sms_test = sms.randomSplit([0.8, 0.2], seed=13)\n",
    "\n",
    "# Fit a Logistic Regression model to the training data\n",
    "logistic = LogisticRegression(regParam=0.2).fit(sms_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "prediction = logistic.transform(sms_test)\n",
    "\n",
    "# Create a confusion matrix, comparing predictions to known labels\n",
    "prediction.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODING FLIGHT ORIGIN\n",
    "\n",
    "\n",
    "# Import the one hot encoder class\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "\n",
    "# Create an instance of the one hot encoder\n",
    "onehot = OneHotEncoderEstimator(inputCols=['org_idx'], outputCols=['org_dummy'])\n",
    "\n",
    "# Apply the one hot encoder to the flights data\n",
    "onehot = onehot.fit(flights)\n",
    "flights_onehot = onehot.transform(flights)\n",
    "\n",
    "# Check the results\n",
    "flights_onehot.select('org', 'org_idx', 'org_dummy').distinct().sort('org_idx').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLIGHT DURATION MODEL JUST DISTANCE\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Create a regression object and train on training data\n",
    "regression = LinearRegression(labelCol='duration' ).fit(flights_train)\n",
    "\n",
    "# Create predictions for the testing data and take a look at the predictions\n",
    "predictions = regression.transform(flights_test)\n",
    "predictions.select('duration', 'prediction').show(5, False)\n",
    "\n",
    "# Calculate the RMSE\n",
    "RegressionEvaluator(labelCol='duration').evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTERPERTING THE COEFFICIENTS\n",
    "\n",
    "# Intercept (average minutes on ground)\n",
    "inter = regression.intercept\n",
    "print(inter)\n",
    "\n",
    "# Coefficients\n",
    "coefs = regression.coefficients\n",
    "print(coefs)\n",
    "\n",
    "# Average minutes per km\n",
    "minutes_per_km = regression.coefficients[0]\n",
    "print(minutes_per_km)\n",
    "\n",
    "# Average speed in km per hour\n",
    "avg_speed = 60 / minutes_per_km\n",
    "print(avg_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLIGHT DURATION MODEL ADDING ORIGIN AIRPORT\n",
    "\n",
    "\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Create a regression object and train on training data\n",
    "regression = LinearRegression(labelCol='duration').fit(flights_train)\n",
    "\n",
    "# Create predictions for the testing data\n",
    "predictions = regression.transform(flights_test)\n",
    "\n",
    "# Calculate the RMSE on testing data\n",
    "RegressionEvaluator(labelCol='duration').evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTERPERTING THE COEFFICIENTS\n",
    "\n",
    "# Average speed in km per hour\n",
    "avg_speed_hour = 60/regression.coefficients[0]\n",
    "print(avg_speed_hour)\n",
    "\n",
    "# Average minutes on ground at OGG\n",
    "inter = regression.intercept\n",
    "print(inter)\n",
    "\n",
    "# Average minutes on ground at JFK\n",
    "avg_ground_jfk = regression.intercept + regression.coefficients[3]\n",
    "print(avg_ground_jfk)\n",
    "\n",
    "# Average minutes on ground at LGA\n",
    "avg_ground_lga = regression.intercept + regression.coefficients[4]\n",
    "print(avg_ground_lga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUCKETING THE DEPARTURE TIME\n",
    "\n",
    "\n",
    "from pyspark.ml.feature import Bucketizer, OneHotEncoderEstimator\n",
    "\n",
    "# Create buckets at 3 hour intervals through the day\n",
    "buckets = Bucketizer(splits=[0, 3, 6, 9, 12, 15, 18, 21, 24], inputCol='depart', outputCol='depart_bucket')\n",
    "\n",
    "# Bucket the departure times\n",
    "bucketed = buckets.transform(flights)\n",
    "bucketed.select('depart', 'depart_bucket').show(5)\n",
    "\n",
    "# Create a one-hot encoder\n",
    "onehot = OneHotEncoderEstimator(inputCols=['depart_bucket'], outputCols=['depart_dummy'])\n",
    "\n",
    "# One-hot encode the bucketed departure times\n",
    "flights_onehot = onehot.fit(bucketed).transform(bucketed)\n",
    "flights_onehot.select('depart', 'depart_bucket', 'depart_dummy').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLIGHT DURATION MODEL ADDING DEPARTURE TIME\n",
    "\n",
    "# Find the RMSE on testing data\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "RegressionEvaluator(labelCol='duration').evaluate(predictions)\n",
    "\n",
    "# Average minutes on ground at OGG for flights departing between 21:00 and 24:00\n",
    "avg_eve_ogg = regression.intercept\n",
    "print(avg_eve_ogg)\n",
    "\n",
    "# Average minutes on ground at OGG for flights departing between 00:00 and 03:00\n",
    "avg_night_ogg = regression.intercept + regression.coefficients[8]\n",
    "print(avg_night_ogg)\n",
    "\n",
    "# Average minutes on ground at JFK for flights departing between 00:00 and 03:00\n",
    "avg_night_jfk = regression.intercept + regression.coefficients[8] + regression.coefficients[3]\n",
    "print(avg_night_jfk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLIGHT DURATION MODEL MORE FEATURES\n",
    "\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Fit linear regression model to training data\n",
    "regression = LinearRegression(labelCol='duration').fit(flights_train)\n",
    "\n",
    "# Make predictions on testing data\n",
    "predictions = regression.transform(flights_test)\n",
    "\n",
    "# Calculate the RMSE on testing data\n",
    "rmse = RegressionEvaluator(labelCol='duration').evaluate(predictions)\n",
    "print(\"The test RMSE is\", rmse)\n",
    "\n",
    "# Look at the model coefficients\n",
    "coeffs = regression.coefficients\n",
    "print(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLIGHT DURATION MODEL REGULARISATION\n",
    "\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Fit Lasso model (α = 1) to training data\n",
    "regression = LinearRegression(labelCol='duration', regParam=1, elasticNetParam=1).fit(flights_train)\n",
    "\n",
    "# Calculate the RMSE on testing data\n",
    "rmse = RegressionEvaluator(labelCol='duration').evaluate(regression.transform(flights_test))\n",
    "print(\"The test RMSE is\", rmse)\n",
    "\n",
    "# Look at the model coefficients\n",
    "coeffs = regression.coefficients\n",
    "print(coeffs)\n",
    "\n",
    "# Number of zero coefficients\n",
    "zero_coeff = sum([beta == 0 for beta in regression.coefficients])\n",
    "print(\"Number of ceofficients equal to 0:\", zero_coeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles and Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLIGHT DURATION MODEL PIPELINE STAGES\n",
    "\n",
    "\n",
    "# Convert categorical strings to index values\n",
    "indexer = StringIndexer(inputCol='org', outputCol='org_idx')\n",
    "\n",
    "# One-hot encode index values\n",
    "onehot = OneHotEncoderEstimator(\n",
    "    inputCols=['org_idx', 'dow'],\n",
    "    outputCols=['org_dummy', 'dow_dummy']\n",
    ")\n",
    "\n",
    "# Assemble predictors into a single column\n",
    "assembler = VectorAssembler(inputCols=['km', 'org_dummy', 'dow_dummy'], outputCol='features')\n",
    "\n",
    "# A linear regression object\n",
    "regression = LinearRegression(labelCol='duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLIGHT DURATION MODEL PIPELIN MODEL\n",
    "\n",
    "# Import class for creating a pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Construct a pipeline\n",
    "pipeline = Pipeline(stages=[indexer,onehot, assembler, regression ])\n",
    "\n",
    "# Train the pipeline on the training data\n",
    "pipeline = pipeline.fit(flights_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "predictions = pipeline.transform(flights_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMS SPAM PIPELINE\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "\n",
    "# Break text into tokens at non-word characters\n",
    "tokenizer = Tokenizer(inputCol='text', outputCol='words')\n",
    "\n",
    "# Remove stop words\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol='terms')\n",
    "\n",
    "# Apply the hashing trick and transform to TF-IDF\n",
    "hasher = HashingTF(inputCol=remover.getOutputCol(), outputCol=\"hash\")\n",
    "idf = IDF(inputCol=hasher.getOutputCol(), outputCol=\"features\")\n",
    "\n",
    "# Create a logistic regression object and add everything to a pipeline\n",
    "logistic = LogisticRegression()\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, hasher, idf, logistic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROSS VALIDATION SIMPLE FLIGHT DURATION MODEL\n",
    "\n",
    "\n",
    "# Create an empty parameter grid\n",
    "params = ParamGridBuilder().build()\n",
    "\n",
    "# Create objects for building and evaluating a regression model\n",
    "regression = LinearRegression(labelCol='duration')\n",
    "evaluator = RegressionEvaluator(labelCol='duration')\n",
    "\n",
    "# Create a cross validator\n",
    "cv = CrossValidator(estimator=regression, estimatorParamMaps=params, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Train and test model on multiple folds of the training data\n",
    "cv = cv.fit(flights_train)\n",
    "\n",
    "# NOTE: Since cross-valdiation builds multiple models, the fit() method can take a little while to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROSS VALIDATING FLIGHT DURATION MODEL PIPELINE\n",
    "\n",
    "\n",
    "# Create an indexer for the org field\n",
    "indexer = StringIndexer(inputCol='org', outputCol='org_idx')\n",
    "\n",
    "# Create an one-hot encoder for the indexed org field\n",
    "onehot = OneHotEncoderEstimator(inputCols=['org_idx'], outputCols=['org_dummy'])\n",
    "\n",
    "# Assemble the km and one-hot encoded fields\n",
    "assembler = VectorAssembler(inputCols=['km', 'org_dummy'], outputCol='features')\n",
    "\n",
    "# Create a pipeline and cross-validator.\n",
    "pipeline = Pipeline(stages=[indexer, onehot, assembler, regression])\n",
    "cv = CrossValidator(estimator=pipeline,\n",
    "          estimatorParamMaps=params,\n",
    "          evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZING FLIGHTS LINEAR REGRESSION\n",
    "\n",
    "\n",
    "# Create parameter grid\n",
    "params = ParamGridBuilder()\n",
    "\n",
    "# Add grids for two parameters\n",
    "params = params.addGrid(regression.regParam, [0.01, 0.1, 1.0, 10.0]) \\\n",
    "               .addGrid(regression.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "\n",
    "# Build the parameter grid\n",
    "params = params.build()\n",
    "print('Number of models to be tested: ', len(params))\n",
    "\n",
    "# Create cross-validator\n",
    "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=params, evaluator=evaluator, numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISSECTING THE BEST FLIGHT DURATION MODEL\n",
    "\n",
    "\n",
    "# Get the best model from cross validation\n",
    "best_model = cv.bestModel\n",
    "\n",
    "# Look at the stages in the best model\n",
    "print(best_model.stages)\n",
    "\n",
    "# Get the parameters for the LinearRegression object in the best model\n",
    "best_model.stages[3].extractParamMap()\n",
    "\n",
    "# Generate predictions on testing data using the best model then calculate RMSE\n",
    "predictions = best_model.transform(flights_test)\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMS SPAM OPTIMIZED\n",
    "\n",
    "\n",
    "# Create parameter grid\n",
    "params = ParamGridBuilder()\n",
    "\n",
    "# Add grid for hashing trick parameters\n",
    "params = params.addGrid(hasher.numFeatures, [1024,4096,16384]) \\\n",
    "               .addGrid(hasher.binary, [True, False])\n",
    "\n",
    "# Add grid for logistic regression parameters\n",
    "params = params.addGrid(logistic.regParam  , [0.01, 0.1, 1.0, 10.0]) \\\n",
    "               .addGrid(logistic.elasticNetParam  , [0.0, 0.5, 1.0])\n",
    "\n",
    "# Build parameter grid\n",
    "params = params.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELAYED FLIGHTS WITH GRADIENT BOOSTED TREES\n",
    "\n",
    "\n",
    "# Import the classes required\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Create model objects and train on training data\n",
    "tree = DecisionTreeClassifier().fit(flights_train)\n",
    "gbt = GBTClassifier().fit(flights_train)\n",
    "\n",
    "# Compare AUC on testing data\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "evaluator.evaluate(tree.transform(flights_test))\n",
    "evaluator.evaluate(gbt.transform(flights_test))\n",
    "\n",
    "# Find the number of trees and the relative importance of features\n",
    "print(gbt.trees)\n",
    "print(gbt.featureImportances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELAYED FLIGHTS WITH A RANDOM FOREST\n",
    "\n",
    "# Create a random forest classifier\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "# Create a parameter grid\n",
    "params = ParamGridBuilder() \\\n",
    "            .addGrid(forest.featureSubsetStrategy, ['all', 'onethird', 'sqrt', 'log2']) \\\n",
    "            .addGrid(forest.maxDepth, [2, 5, 10]) \\\n",
    "            .build()\n",
    "\n",
    "# Create a binary classification evaluator\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "# Create a cross-validator\n",
    "cv = CrossValidator(estimator=forest, estimatorParamMaps=params, evaluator=evaluator, numFolds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATING A RANDOM FOREST\n",
    "\n",
    "\n",
    "# Average AUC for each parameter combination in grid\n",
    "avg_auc = cv.avgMetrics\n",
    "\n",
    "# Average AUC for the best model\n",
    "best_model_auc =  max(avg_auc)\n",
    "\n",
    "# What's the optimal parameter value?\n",
    "opt_max_depth = cv.bestModel.explainParam('maxDepth')\n",
    "opt_feat_substrat = cv.bestModel.explainParam('featureSubsetStrategy')\n",
    "\n",
    "# AUC for best model on testing data\n",
    "best_auc = evaluator.evaluate(cv.transform(flights_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
