{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing Image Processing and scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB TO GRAYSCALE\n",
    "\n",
    "# Import the modules from skimage\n",
    "from skimage import data, color\n",
    "\n",
    "# Load the rocket image\n",
    "rocket = data.rocket()\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray_scaled_rocket = color.rgb2gray(rocket)\n",
    "\n",
    "# Show the original image\n",
    "show_image(rocket, 'Original RGB image')\n",
    "\n",
    "# Show the grayscale image\n",
    "show_image(gray_scaled_rocket, 'Grayscale image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLIPPING OUT\n",
    "\n",
    "# Flip the image vertically\n",
    "seville_vertical_flip = np.flipud(flipped_seville)\n",
    "\n",
    "# Flip the image horizontally\n",
    "seville_horizontal_flip = np.fliplr(seville_vertical_flip)\n",
    "\n",
    "# Show the resulting image\n",
    "show_image(seville_horizontal_flip, 'Seville')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HISTOGRAMS\n",
    "\n",
    "\n",
    "# Obtain the red channel\n",
    "red_channel = image[:, :, 0]\n",
    "\n",
    "# Plot the red histogram with bins in a range of 256\n",
    "plt.hist(red_channel.ravel(), bins=256)\n",
    "\n",
    "# Set title and show\n",
    "plt.title('Red Histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLY GLOBAL THRESHOLDING\n",
    "\n",
    "\n",
    "# Import the otsu threshold function\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "# Make the image grayscale using rgb2gray\n",
    "chess_pieces_image_gray = rgb2gray(chess_pieces_image)\n",
    "\n",
    "# Obtain the optimal threshold value with otsu\n",
    "thresh = threshold_otsu(chess_pieces_image_gray)\n",
    "\n",
    "# Apply thresholding to the image\n",
    "binary = chess_pieces_image_gray > thresh\n",
    "\n",
    "# Show the image\n",
    "show_image(binary, 'Binary image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHEN THE BACKGROUND ISNT THAT OBVIOUS\n",
    "\n",
    "\n",
    "# Import the otsu threshold function\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "# Obtain the optimal otsu global thresh value\n",
    "global_thresh = threshold_otsu(page_image)\n",
    "\n",
    "# Obtain the binary image by applying global thresholding\n",
    "binary_global = page_image > global_thresh\n",
    "\n",
    "# Show the binary image obtained\n",
    "show_image(binary_global, 'Global thresholding')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Import the local threshold function\n",
    "from skimage.filters import threshold_local\n",
    "\n",
    "# Set the block size to 35\n",
    "block_size = 35\n",
    "\n",
    "# Obtain the optimal local thresholding\n",
    "local_thresh = threshold_local(page_image, block_size, offset=10)\n",
    "\n",
    "# Obtain the binary image by applying local thresholding\n",
    "binary_local = page_image > local_thresh\n",
    "\n",
    "# Show the binary image\n",
    "show_image(binary_local, 'Local thresholding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRYING OTHER METHODS\n",
    "\n",
    "\n",
    "# Import the try all function\n",
    "from skimage.filters import try_all_threshold\n",
    "\n",
    "# Import the rgb to gray convertor function \n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "# Turn the fruits image to grayscale\n",
    "grayscale = color.rgb2gray(fruits_image)\n",
    "\n",
    "# Use the try all method on the grayscale image\n",
    "fig, ax = try_all_threshold(grayscale, verbose=False)\n",
    "\n",
    "# Show the resulting plots\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLYING THRESHOLDING\n",
    "\n",
    "\n",
    "# Import threshold and gray convertor functions\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "# Turn the image grayscale\n",
    "gray_tools_image = rgb2gray(tools_image)\n",
    "\n",
    "# Obtain the optimal thresh\n",
    "thresh = threshold_otsu(gray_tools_image)\n",
    "\n",
    "# Obtain the binary image by applying thresholding\n",
    "binary_image = gray_tools_image > thresh\n",
    "\n",
    "# Show the resulting binary image\n",
    "show_image(binary_image, 'Binarized image')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filters, Contrast, Transformation and Morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDGE DETECTION\n",
    "\n",
    "\n",
    "# Import the color module\n",
    "from skimage import color\n",
    "\n",
    "# Import the filters module and sobel function\n",
    "from skimage.filters import sobel\n",
    "\n",
    "# Make the image grayscale\n",
    "soaps_image_gray = color.rgb2gray(soaps_image)\n",
    "\n",
    "# Apply edge detection filter\n",
    "edge_sobel = sobel(soaps_image_gray)\n",
    "\n",
    "# Show original and resulting image to compare\n",
    "show_image(soaps_image, \"Original\")\n",
    "show_image(edge_sobel, \"Edges with Sobel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLURRING TO REDUCE NOISE\n",
    "\n",
    "\n",
    "# Import Gaussian filter \n",
    "from skimage.filters import gaussian\n",
    "\n",
    "# Apply filter\n",
    "gaussian_image = gaussian(building_image, multichannel=True)\n",
    "\n",
    "# Show original and resulting image to compare\n",
    "show_image(building_image, \"Original\")\n",
    "show_image(gaussian_image, \"Reduced sharpness Gaussian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEDICAL IMAGES\n",
    "\n",
    "\n",
    "# Import the required module\n",
    "from skimage import exposure\n",
    "\n",
    "# Show original x-ray image and its histogram\n",
    "show_image(chest_xray_image, 'Original x-ray')\n",
    "\n",
    "plt.title('Histogram of image')\n",
    "plt.hist(chest_xray_image.ravel(), bins=256)\n",
    "plt.show()\n",
    "\n",
    "# Use histogram equalization to improve the contrast\n",
    "xray_image_eq =  exposure.equalize_hist(chest_xray_image)\n",
    "\n",
    "# Show the resulting image\n",
    "show_image(xray_image_eq, 'Resulting image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AEIRIAL IMAGE\n",
    "\n",
    "\n",
    "# Import the required module\n",
    "from skimage import exposure\n",
    "\n",
    "# Use histogram equalization to improve the contrast\n",
    "image_eq =  exposure.equalize_hist(image_aerial)\n",
    "\n",
    "# Show the original and resulting image\n",
    "show_image(image_aerial, 'Original')\n",
    "show_image(image_eq, 'Resulting image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LETS ADD SOME IMPACT AND CONTRAST\n",
    "\n",
    "\n",
    "# Import the necessary modules\n",
    "from skimage import data, exposure\n",
    "\n",
    "# Load the image\n",
    "original_image = data.coffee()\n",
    "\n",
    "# Apply the adaptive equalization on the original image\n",
    "adapthist_eq_image = exposure.equalize_adapthist(original_image, clip_limit=0.03)\n",
    "\n",
    "# Compare the original image to the equalized\n",
    "show_image(original_image)\n",
    "show_image(adapthist_eq_image, '#ImageProcessingDatacamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALIASING ROTATING AND RESCALING\n",
    "\n",
    "\n",
    "# Import the module and the rotate and rescale functions\n",
    "from skimage.transform import rotate, rescale\n",
    "\n",
    "# Rotate the image 90 degrees clockwise \n",
    "rotated_cat_image = rotate(image_cat, -90)\n",
    "\n",
    "# Rescale with anti aliasing\n",
    "rescaled_with_aa = rescale(rotated_cat_image, 1/4, anti_aliasing=True, multichannel=True)\n",
    "\n",
    "# Rescale without anti aliasing\n",
    "rescaled_without_aa = rescale(rotated_cat_image, 1/4, anti_aliasing=False, multichannel=True)\n",
    "\n",
    "# Show the resulting images\n",
    "show_image(rescaled_with_aa, \"Transformed with anti aliasing\")\n",
    "show_image(rescaled_without_aa, \"Transformed without anti aliasing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENLARGING IMAGES\n",
    "\n",
    "\n",
    "# Import the module and function to enlarge images\n",
    "from skimage.transform import rescale\n",
    "\n",
    "# Import the data module\n",
    "from skimage import data\n",
    "\n",
    "# Load the image from data\n",
    "rocket_image = data.rocket()\n",
    "\n",
    "# Enlarge the image so it is 3 times bigger\n",
    "enlarged_rocket_image = rescale(rocket_image,3, anti_aliasing=True, multichannel=True)\n",
    "\n",
    "# Show original and resulting image\n",
    "show_image(rocket_image)\n",
    "show_image(enlarged_rocket_image, \"3 times enlarged image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROPORTIONALLY RESIZING\n",
    "\n",
    "\n",
    "# Import the module and function\n",
    "from skimage.transform import resize\n",
    "\n",
    "# Set proportional height so its half its size\n",
    "height = int(dogs_banner.shape[0] / 2)\n",
    "width = int(dogs_banner.shape[1] / 2)\n",
    "\n",
    "# Resize using the calculated proportional height and width\n",
    "image_resized = resize(dogs_banner, (height, width),\n",
    "                       anti_aliasing=True)\n",
    "\n",
    "# Show the original and rotated image\n",
    "show_image(dogs_banner, 'Original')\n",
    "show_image(image_resized, 'Resized image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDWRITTEN LETTERS\n",
    "\n",
    "# Import the morphology module\n",
    "from skimage import morphology\n",
    "\n",
    "# Obtain the eroded shape \n",
    "eroded_image_shape = morphology.binary_erosion(upper_r_image) \n",
    "\n",
    "# See results\n",
    "show_image(upper_r_image, 'Original')\n",
    "show_image(eroded_image_shape, 'Eroded image')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVING THE THRESHOLD IMAGE\n",
    "\n",
    "\n",
    "# Import the module\n",
    "from skimage import morphology\n",
    "\n",
    "# Obtain the dilated image \n",
    "dilated_image = morphology.dilation(world_image)\n",
    "\n",
    "# See results\n",
    "show_image(world_image, 'Original')\n",
    "show_image(dilated_image, 'Dilated image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image restoration, Noise, Segmentation and Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LETS RESTORE A DAMAGED IMAGE\n",
    "\n",
    "\n",
    "# Import the module from restoration\n",
    "from skimage.restoration import inpaint\n",
    "\n",
    "# Show the defective image\n",
    "show_image(defect_image, 'Image to restore')\n",
    "\n",
    "# Apply the restoration function to the image using the mask\n",
    "restored_image = inpaint.inpaint_biharmonic(defect_image, mask, multichannel=True)\n",
    "show_image(restored_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVING LOGOS\n",
    "\n",
    "\n",
    "# Initialize the mask\n",
    "mask = np.zeros(image_with_logo.shape[:-1])\n",
    "\n",
    "# Set the pixels where the logo is to 1\n",
    "mask[210:272, 360:425] = 1\n",
    "\n",
    "# Apply inpainting to remove the logo\n",
    "image_logo_removed = inpaint.inpaint_biharmonic(image_with_logo,\n",
    "                                  mask,\n",
    "                                  multichannel=True)\n",
    "\n",
    "# Show the original and logo removed images\n",
    "show_image(image_with_logo, 'Image with logo')\n",
    "show_image(image_logo_removed, 'Image with logo removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LETS MAKE SOME NOISE\n",
    "\n",
    "# Import the module and function\n",
    "from skimage.util import random_noise\n",
    "\n",
    "# Add noise to the image\n",
    "noisy_image = random_noise(fruit_image)\n",
    "\n",
    "# Show original and resulting image\n",
    "show_image(fruit_image, 'Original')\n",
    "show_image(noisy_image, 'Noisy image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REDUCING NOISE\n",
    "\n",
    "\n",
    "# Import the module and function\n",
    "from skimage.restoration import denoise_tv_chambolle\n",
    "\n",
    "# Apply total variation filter denoising\n",
    "denoised_image = denoise_tv_chambolle(noisy_image, \n",
    "                                      multichannel=True)\n",
    "\n",
    "# Show the noisy and denoised images\n",
    "show_image(noisy_image, 'Noisy')\n",
    "show_image(denoised_image, 'Denoised image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REDUCING NOISE WHILE PRESERVING EDGES\n",
    "\n",
    "\n",
    "# Import bilateral denoising function\n",
    "from skimage.restoration import denoise_bilateral\n",
    "\n",
    "# Apply bilateral filter denoising\n",
    "denoised_image = denoise_bilateral(landscape_image, \n",
    "                                   multichannel=True)\n",
    "\n",
    "# Show original and resulting images\n",
    "show_image(landscape_image, 'Noisy image')\n",
    "show_image(denoised_image, 'Denoised image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUPER PIXEL SEGMENTATION. \n",
    "\n",
    "# Import the slic function from segmentation module\n",
    "from skimage.segmentation import slic\n",
    "\n",
    "# Import the label2rgb function from color module\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "# Obtain the segmentation with 400 regions\n",
    "segments = slic(face_image, n_segments= 400)\n",
    "\n",
    "# Put segments on top of original image to compare\n",
    "segmented_image = label2rgb(segments, face_image, kind='avg')\n",
    "\n",
    "# Show the segmented image\n",
    "show_image(segmented_image, \"Segmented image, 400 superpixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTOURING SHAPES\n",
    "\n",
    "\n",
    "# Import the modules\n",
    "from skimage import data, measure\n",
    "\n",
    "# Obtain the horse image\n",
    "horse_image = data.horse()\n",
    "\n",
    "# Find the contours with a constant level value of 0.8\n",
    "contours = measure.find_contours(horse_image, 0.8)\n",
    "\n",
    "# Shows the image with contours found\n",
    "show_image_contour(horse_image, contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIND CONTOURS FROM NON BINARY IMAGE\n",
    "\n",
    "\n",
    "# Make the image grayscale\n",
    "image_dices = color.rgb2gray(image_dices)\n",
    "\n",
    "# Obtain the optimal thresh value\n",
    "thresh = filters.threshold_otsu(image_dices)\n",
    "\n",
    "# Apply thresholding\n",
    "binary = image_dices > thresh\n",
    "\n",
    "# Find contours at a constant value of 0.8\n",
    "contours = measure.find_contours(binary, 0.8)\n",
    "\n",
    "# Show the image\n",
    "show_image_contour(image_dices, contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COUNT THE DOTS IN DICE IMAGE\n",
    "\n",
    "\n",
    "# Create list with the shape of each contour \n",
    "shape_contours = [cnt.shape[0] for cnt in contours]\n",
    "\n",
    "# Set 50 as the maximum size of the dots shape\n",
    "max_dots_shape = 50\n",
    "\n",
    "# Count dots in contours excluding bigger than dots size\n",
    "dots_contours = [cnt for cnt in contours if np.shape(cnt)[0] < max_dots_shape]\n",
    "\n",
    "# Shows all contours found \n",
    "show_image_contour(binary, contours)\n",
    "\n",
    "# Print the dice's number\n",
    "print(\"Dice's dots number: {}. \".format(len(dots_contours)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Operations, Detecting Faces and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDGES\n",
    "\n",
    "\n",
    "\n",
    "# Import the canny edge detector \n",
    "from skimage.feature import canny\n",
    "\n",
    "# Convert image to grayscale\n",
    "grapefruit = color.rgb2gray(grapefruit)\n",
    "\n",
    "# Apply canny edge detector\n",
    "canny_edges = canny(grapefruit)\n",
    "\n",
    "# Show resulting image\n",
    "show_image(canny_edges, \"Edges with Canny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LESS EDGY\n",
    "\n",
    "\n",
    "# Apply canny edge detector with a sigma of 1.8\n",
    "edges_1_8 = canny(grapefruit, sigma=1.8)\n",
    "\n",
    "# Apply canny edge detector with a sigma of 2.2\n",
    "edges_2_2 = canny(grapefruit, sigma=2.2)\n",
    "\n",
    "# Show resulting images\n",
    "show_image(edges_1_8, \"Sigma of 1.8\")\n",
    "show_image(edges_2_2, \"Sigma of 2.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERSPECTIVE\n",
    "\n",
    "# Import the corner detector related functions and module\n",
    "from skimage.feature import corner_harris, corner_peaks\n",
    "\n",
    "# Convert image from RGB-3 to grayscale\n",
    "building_image_gray = color.rgb2gray(building_image)\n",
    "\n",
    "# Apply the detector  to measure the possible corners\n",
    "measure_image = corner_harris(building_image_gray)\n",
    "\n",
    "# Find the peaks of the corners using the Harris detector\n",
    "coords = corner_peaks(measure_image, min_distance=2)\n",
    "\n",
    "# Show original and resulting image with corners detected\n",
    "show_image(building_image, \"Original\")\n",
    "show_image_with_corners(building_image, coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LESS CORNERS\n",
    "\n",
    "\n",
    "# Find the peaks with a min distance of 2 pixels\n",
    "coords_w_min_2 = corner_peaks(measure_image, min_distance=2)\n",
    "print(\"With a min_distance setted to 2, we detect a total\", len(coords_w_min_2), \"corners in the image.\")\n",
    "\n",
    "# Find the peaks with a min distance of 40 pixels\n",
    "coords_w_min_40 = corner_peaks(measure_image, min_distance=40)\n",
    "print(\"With a min_distance setted to 40, we detect a total\", len(coords_w_min_40), \"corners in the image.\")\n",
    "\n",
    "# Show original and resulting image with corners detected\n",
    "show_image_with_corners(building_image, coords_w_min_2, \"Corners detected with 2 px of min_distance\")\n",
    "show_image_with_corners(building_image, coords_w_min_40, \"Corners detected with 40 px of min_distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IS SOMEONE THERE?\n",
    "\n",
    "# Load the trained file from data\n",
    "trained_file = data.lbp_frontal_face_cascade_filename()\n",
    "\n",
    "# Initialize the detector cascade\n",
    "detector = Cascade(trained_file)\n",
    "\n",
    "# Detect faces with min and max size of searching window\n",
    "detected = detector.detect_multi_scale(img = night_image,\n",
    "                                       scale_factor=1.2,\n",
    "                                       step_ratio=1,\n",
    "                                       min_size=(10, 10),\n",
    "                                       max_size=(200, 200))\n",
    "\n",
    "# Show the detected faces\n",
    "show_detected_face(night_image, detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTIPLE FACES\n",
    "\n",
    "# Load the trained file from data\n",
    "trained_file = data.lbp_frontal_face_cascade_filename()\n",
    "\n",
    "# Initialize the detector cascade\n",
    "detector = Cascade(trained_file)\n",
    "\n",
    "# Detect faces with scale factor to 1.2 and step ratio to 1\n",
    "detected = detector.detect_multi_scale(img=friends_image,\n",
    "                                       scale_factor=1.2,\n",
    "                                       step_ratio=1,\n",
    "                                       min_size=(10, 10),\n",
    "                                       max_size=(200, 200))\n",
    "# Show the detected faces\n",
    "show_detected_face(friends_image, detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEGMENTATION AND FACE DETTECTION\n",
    "\n",
    "\n",
    "# Obtain the segmentation with default 100 regions\n",
    "segments = slic(profile_image, n_segments=100)\n",
    "\n",
    "# Obtain segmented image using label2rgb\n",
    "segmented_image = label2rgb(segments, profile_image, kind='avg')\n",
    "\n",
    "# Detect the faces with multi scale method\n",
    "detected = detector.detect_multi_scale(img=segmented_image, \n",
    "                                       scale_factor=1.2, \n",
    "                                       step_ratio=1, \n",
    "                                       min_size=(10, 10), max_size=(1000, 1000))\n",
    "\n",
    "# Show the detected faces\n",
    "show_detected_face(segmented_image, detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRIVACY PROTECTION\n",
    "\n",
    "# Detect the faces\n",
    "detected = detector.detect_multi_scale(img=group_image, \n",
    "                                       scale_factor=1.2, step_ratio=1, \n",
    "                                       min_size=(10,10), max_size=(100, 100))\n",
    "# For each detected face\n",
    "for d in detected:  \n",
    "    # Obtain the face rectangle from detected coordinates\n",
    "    face = getFaceRectangle(d)\n",
    "    \n",
    "    # Apply gaussian filter to extracted face\n",
    "    blurred_face = gaussian(face, multichannel=True, sigma = 8)\n",
    "    \n",
    "    # Merge this blurry face to our final image and show it\n",
    "    resulting_image = mergeBlurryFace(group_image, blurred_face) \n",
    "show_image(resulting_image, \"Blurred faces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELP SALLY RESTORE HER GRADUATION PHOTO\n",
    "\n",
    "\n",
    "# Import the necessary modules\n",
    "from skimage.restoration import denoise_tv_chambolle, inpaint\n",
    "from skimage.transform import rotate\n",
    "\n",
    "# Transform the image so it's not rotated\n",
    "upright_img = rotate(damaged_image, 20)\n",
    "\n",
    "# Remove noise from the image, using the chambolle method\n",
    "upright_img_without_noise = denoise_tv_chambolle(upright_img,weight=0.1, multichannel=True)\n",
    "\n",
    "# Reconstruct the image missing parts\n",
    "mask = get_mask(upright_img)\n",
    "result = inpaint.inpaint_biharmonic(upright_img_without_noise, mask, multichannel=True)\n",
    "\n",
    "show_image(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
